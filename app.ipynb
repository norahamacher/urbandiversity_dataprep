{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports and defs\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from numpy.core import shape_base\n",
    "#some required libraries for the conversion.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import jenkspy\n",
    "import json\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import os\n",
    "import copy\n",
    "import math\n",
    "from shapely.geometry import Polygon\n",
    "import io\n",
    "from ipyvuetify.extra import FileInput\n",
    "\n",
    "\n",
    "enddata = {}\n",
    "#converts the value to numeric (int if int, else float). \n",
    "#returns -1 if:\n",
    "#   a) the value is not numeric, check for strings reflecting numeric values is implemented\n",
    "#   b) if the value is nan\n",
    "def makeFloat(val):\n",
    "\n",
    "      if(isinstance(val,float)):\n",
    "        if(math.isnan(val)):\n",
    "          return -1\n",
    "        else:\n",
    "          return val\n",
    "      elif (isinstance(val,int)):\n",
    "        if(math.isnan(val)):\n",
    "          return -1\n",
    "        else:\n",
    "          return val\n",
    "      else: #string\n",
    "        try:\n",
    "          res = float(val)\n",
    "          if(math.isnan(res)):\n",
    "            return -1\n",
    "          else:\n",
    "            return res\n",
    "        except ValueError:  #casting not possible --> not a numeric value in the string\n",
    "          return -1\n",
    "\n",
    "#mediator function to call jenkspy jenks calculation\n",
    "def getJenks(arr,num):\n",
    "      return jenkspy.jenks_breaks(arr, nb_class=num)\n",
    "\n",
    "#get the jenks values from the jenksVals, which have been aggregated per parameters.\n",
    "def makeJenks(data, jenksVals):\n",
    "      enddata= data\n",
    "      currJson={}\n",
    "      range = [12] #Jenks steps to be used\n",
    "      #print(data.keys())\n",
    "      currJson[\"all\"]={}\n",
    "      for key in jenksVals.keys():\n",
    "        currJson[\"all\"][key] = {} \n",
    "        for val in range:\n",
    "          currJson[\"all\"][key][val] = getJenks(jenksVals[key], val)  \n",
    "\n",
    "      enddata[\"jenks\"] = currJson  #attach the jenks values to the data.\n",
    "      #print(data.keys())\n",
    "      #print(data)\n",
    "      #textoutput = json.dumps(data)\n",
    "      result = widgets.Textarea(\n",
    "        value=str(enddata),\n",
    "        placeholder='Waiting for output...',\n",
    "        description='Result:',\n",
    "        disabled=False,\n",
    "        layout=widgets.Layout(width='80%', height=\"500px\")\n",
    "        )\n",
    "      display(result)\n",
    "      print(\"Finished jenks. Result is in the result textarea.\")\n",
    "      #with open(\"./\"+ name +'_withjenks.json', 'w') as f: #dump the data in the new file.\n",
    "      #  f.write(json.dumps(data, separators=(',', ':')))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Knhupb2U3E0R"
   },
   "source": [
    "<h1> Preprocessing for the urban diversity web tools </h1>\n",
    "\n",
    "The urban superdiversity web tool requires a certain format of json to read data. You can create the format yourself or use the tools provided in this notebook. \n",
    "Below, find an example of the data used in the web app, with explaning comments. If you only wanted to know how the data is supposed to look like, you've found it and won't need the rest of this notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TAfOlmqk3xBp"
   },
   "source": [
    "\n",
    "\n",
    "```\n",
    "{\"type\":\"FeatureCollection\",    //geojson format\n",
    "\"cityYear\":\"Vancouver-2006\",\n",
    "\"features\":[                    //each data point is in the features array. \n",
    "  {\"type\":\"Feature\",            //each data point is its own object, always type feature\n",
    "  \"properties\":{                //properties are copied from the shape file information\n",
    "    \"DAUID\":\"59150004\",\n",
    "    \"CSDUID\":\"5915055\",\n",
    "    \"CCSUID\":\"5915020\",\n",
    "    \"CDUID\":\"5915\",\n",
    "    \"ERUID\":\"5920\",\n",
    "    \"PRUID\":\"59\",\n",
    "    \"CTUID\":\"9330133.01\",\n",
    "    \"CMAUID\":\"933\",\"\n",
    "    indices\":{                  //indices is what was provided in the data csv file.\n",
    "      \"Population\":353,\n",
    "      \"Ethnicity-raw-count\":22,\n",
    "      \"Ethnicity-raw-normalized\":0.062323,\n",
    "      \"Mobility-raw-pct\":36.619718,\n",
    "      \"Generation-raw-SI\":0.732222,\n",
    "      \"Education-raw-SI\":0.796875,\n",
    "      \"Income-raw-SI\":0.865077}\n",
    "      },\n",
    "    \"geometry\":{               // point is the centroid of the polygon in the shapefile\n",
    "      \"type\":\"Point\",\n",
    "      \"coordinates\":[-123.25887520351195,49.38854863564009]},\n",
    "    \"geom_store\":{\n",
    "      \"type\":\"Polygon\",\n",
    "      \"coordinates\":[[[a,b],   //left out the proper coordinates, but this is an array of many lat/lon tuples\n",
    "  [c,d],\n",
    "  [...]]]}},\n",
    "  {...},\n",
    "  {...},\n",
    "  {...}]}                           this array of object contains all data points used on the map later.\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfLN0pI_5Uwh"
   },
   "source": [
    "<h3>Data format needed for these scripts to work</h3>\n",
    "\n",
    "\n",
    "\n",
    "*   A shapefile, converted to geojson (use a program like ArcGIS to do this)\n",
    "*   A csv file containing all the parameters/indices you want to analyse. One column of this csv file MUST identify the matching parameter to the shape file. This is what the two files will be merged on.\n",
    "\n",
    "<h4> Step 1 </h4>\n",
    "Upload the two files here , by clicking on the upload icon below \"Files\" in the left menu. The scripts expect one file ending in .csv and one ending in .json.\n",
    "\n",
    "<h4> Step 2</h4>\n",
    "Provide the names for the matching parameter in both files. Please type the names in the form below, which have been populated with sample names. The csv_comparator should be the column name in your csv file which contains the list of entities, while the geojson_comparator should be the property within the file that matches the data in the csv column. \n",
    "You can also provide a meaningful name for your dataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processfiles(json_data, csv_data):\n",
    "    print(\"Processing started...\")\n",
    "    #print(json_data)\n",
    "    #print(csv_data)\n",
    "    df_shape={}\n",
    "    df_indices={}\n",
    "    csv_comp = csv_comparator.value\n",
    "    json_comp = json_comparator.value\n",
    "    try:\n",
    "        df_indices = pd.DataFrame.from_dict(pd.read_csv(csv_data))\n",
    "        print(\"Loaded csv.\")\n",
    "        #print(df_indices)\n",
    "    except IOError:\n",
    "        print(\"Error loading csv.\")   \n",
    "    \n",
    "    #read the geojson (sometimes only json ending)\n",
    " \n",
    "    try:\n",
    "        df_shape = pd.read_json(json_data)\n",
    "        print(\"Loaded json\")\n",
    "    except IOError:\n",
    "        print(\"Error while loading geojson.\") \n",
    "   \n",
    "    #print(csv_comp)\n",
    "    #print(json_comp)\n",
    "    #print(df_indices)\n",
    "    #print(df_indices.loc[df_indices[csv_comp]==59150630.0])\n",
    "    for feat in df_shape['features']:\n",
    "    #Merging code. Grabs the row from the csv that matches the geojson_comparator from each entry in the geojson and puts the \n",
    "    #indices in a new  indices property.\n",
    "        #print(type(feat))\n",
    "        feat[\"properties\"][\"indices\"] = {}\n",
    "        #print(feat[\"properties\"][json_comp])\n",
    "        row = df_indices.loc[df_indices[csv_comp]==makeFloat(feat[\"properties\"][json_comp])]  #find the correct row\n",
    "        rowDict = row.to_dict(orient='records')\n",
    "        if len(rowDict)>0:\n",
    "            #print(rowDict)\n",
    "            for key in rowDict[0]:  #go through the keys and add them to the json object.\n",
    "                if (key.find(\"ndex\") < 0) & (key!=csv_comp):\n",
    "                  #print(row[key])\n",
    "                    val = makeFloat(row[key])  #TODO: This needs to change if we're ever going to use non-numerical values in \n",
    "                    #our evaluations. \n",
    "                    feat[\"properties\"][\"indices\"][key] = round(val,6)\n",
    "    \n",
    "    print(\"Finished merging. Starting geometry calculations.\")\n",
    "    #create the new resulting json.\n",
    "    newJson = {}\n",
    "    newJson[\"type\"] = \"FeatureCollection\"\n",
    "    newJson[\"cityYear\"] = name\n",
    "    newJson[\"features\"] = []\n",
    "\n",
    "    #write the data to the new geojson object. Also adds centroid property for the geometry\n",
    "    for feat in df_shape.features:\n",
    "\n",
    "          obj = {\"type\": \"Feature\", \"properties\": feat[\"properties\"],\"geometry\":feat[\"geometry\"]}\n",
    "           #create the centroid for the data points\n",
    "          geometry = obj[\"geometry\"]\n",
    "          #print(geometry)\n",
    "          if (type( geometry['coordinates'][0][0][0] ) is float):\n",
    "            P = Polygon(geometry['coordinates'][0])\n",
    "          else :\n",
    "            P = Polygon(geometry['coordinates'][0][0])\n",
    "          circle = P.centroid\n",
    "\n",
    "          geometry_ = {\"type\":\"Point\",\"coordinates\":[circle.x,circle.y]}\n",
    "          obj[\"geometry\"]=geometry_\n",
    "          obj[\"geom_store\"] = geometry\n",
    "          newJson[\"features\"].append(obj)\n",
    "\n",
    "    df_shape = newJson\n",
    "    #print(\"Generated file: \")\n",
    "    #print(json.dumps(df_shape))\n",
    "    #result.value = json.dumps(df_shape)\n",
    "    #with open(\"./\"+ name +'.json', 'w') as f: #dump the data in the new file.\n",
    "    #    f.write(json.dumps(df_shape, separators=(',', ':')))\n",
    "        \n",
    "    print(\"Finished. Starting Jenks calculations.\")\n",
    "    #jenks\n",
    "    arr = {\"name\":name, \"all\": {}}\n",
    "    #aggregate all values for all parameters in an array per parameter, which will be used for the jenks calculation.\n",
    "    #in the same loop, we also caluclate the centroid for each polygon which is used for the bars in the multiviz tool.\n",
    "    for feat in df_shape[\"features\"]:\n",
    "\n",
    "      for key in feat['properties']['indices'].keys(): #go through all the indices\n",
    "          val = feat['properties']['indices'][key]\n",
    "\n",
    "          if (key in arr['all'].keys()):  #is this index alread in the result? then add to that key\n",
    "            if (val >=0 ): \n",
    "              arr['all'][key].append(val)\n",
    "          else:\n",
    "            if (val >=0 ) :\n",
    "                arr['all'][key] = []\n",
    "                arr['all'][key].append(val)\n",
    "\n",
    "    makeJenks(df_shape,arr[\"all\"]) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0hHUuS3RI7gq"
   },
   "source": [
    "#### Troubleshooting \n",
    "\n",
    "\n",
    "*   Code fails to execute: Please read the error message. The most likely culprits are: Could not find csv or json file.\n",
    "*   Resulting file does not show any of the indices in the csv! Please make sure you provided the correct spelling (case sensitive) for the column name in the csv for the geographical entity you want to  match and the same for the parameter in the shape file. The format of both parameters must be the same too - not floats for one and int for the other, there will be a direct comparison, as some will be strings, and others not, so make sure your index data is prepped accordingly and matches the shape file (or vice versa).\n",
    "*   Jenks calculation fails: Only numerical values work. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c809e448f9bd490b9a057ed3f92a09de",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileInput(events=['upload'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "file_input_json = FileInput(placeholder=\"Select JSON\")\n",
    "file_input_json\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Upload CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "685c3ede8bd946e9b768a5bf1e65ddec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "FileInput(events=['upload'])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "file_input_csv = FileInput(label=\"Select CSV\")\n",
    "file_input_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0ef9b6817cf4a0cb1174863ee8069e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='CSVfile Comparator   ', layout=Layout(height='40px', width='50%'), style=Descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7db52e1af3354e079b3d58557eef58dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='GEOJSON Comparator', layout=Layout(height='40px', width='50%'), style=DescriptionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1144530db6e84dd89f53e7acd7fbf83b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='result', description='Dataset name', layout=Layout(height='40px', width='50%'), style=DescriptionS…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "csv_comparator = widgets.Text(\n",
    "    description=\"CSVfile Comparator   \",\n",
    "    style ={'description_width': 'initial'},\n",
    "    disabled=False,\n",
    "    layout = widgets.Layout(width='50%',height='40px')\n",
    ")\n",
    "\n",
    "json_comparator = widgets.Text(\n",
    "    description=\"GEOJSON Comparator\",\n",
    "    style ={'description_width': 'initial'},\n",
    "    disabled=False,\n",
    "    layout = widgets.Layout(width='50%',height='40px')\n",
    ")\n",
    "\n",
    "name = widgets.Text(\n",
    "    value = \"result\",\n",
    "    style ={'description_width': 'initial'},\n",
    "    description=\"Dataset name\",\n",
    "    disabled=False,\n",
    "    layout = widgets.Layout(width='50%',height='40px')\n",
    ")\n",
    "display(csv_comparator)\n",
    "display(json_comparator)\n",
    "display(name)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#processfiles(json_data, file2[0][\"file_obj\"].read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ac3ae56547640b4ac5b5c0ec6ff989e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Do Magic!', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8be2c39e07484599ac70eb3173409116",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from io import StringIO\n",
    "button = widgets.Button(description=\"Do Magic!\")\n",
    "output = widgets.Output()\n",
    "display(button, output)\n",
    "\n",
    "def callfunction(a):\n",
    "    file = file_input_json.get_files()\n",
    "    file2 = file_input_csv.get_files()\n",
    "    csvString = StringIO(file2[0][\"file_obj\"].read().decode(\"utf-8\"))\n",
    "    processfiles(file[0][\"file_obj\"].read(),csvString)\n",
    "    #print(enddata)\n",
    "    \n",
    "button.on_click(callfunction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Superdiversity Preprocessing.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
